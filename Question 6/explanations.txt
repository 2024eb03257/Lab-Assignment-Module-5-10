EXPLANATION

COMMAND-BY-COMMAND BREAKDOWN

1. [ $# -ne 1 ]
   - $# : Number of command-line arguments passed to script
   - -ne 1 : "Not equal to 1" comparison
   - Checks if exactly one argument (filename) was provided
   - Example: ./metrics.sh input.txt → $# is 1 (correct)
              ./metrics.sh → $# is 0 (error)

2. echo "Usage: $0 <file>" && exit 1
   - $0 : Name of the script itself
   - && : "AND" operator - execute next command if previous succeeds
   - exit 1 : Exit with error code 1 (indicates failure)
   - Shows usage message and exits if wrong number of arguments

3. [ ! -f "$1" ]
   - $1 : First command-line argument (the filename)
   - -f : Test if file exists and is a regular file
   - ! : Negation (NOT operator)
   - Combined: "if file does NOT exist"
   - Example: ./metrics.sh missing.txt → returns true, shows error

4. [ ! -s "$1" ]
   - -s : Test if file exists and has size greater than zero
   - ! : NOT operator
   - Combined: "if file is empty or doesn't exist"
   - Prevents processing empty files

5. tr '[:upper:]' '[:lower:]'
   - Translates (converts) characters
   - [:upper:] : Character class for uppercase A-Z
   - [:lower:] : Character class for lowercase a-z
   - Converts all text to lowercase for consistent comparison
   - Example: "Hello WORLD" → "hello world"

6. < "$1"
   - Input redirection
   - Reads content from file $1 and feeds it to tr command
   - Alternative to: cat "$1" | tr ... (but more efficient)

7. tr -s '[:space:][:punct:]' '\n'
   - -s : Squeeze (replace sequences of characters with single instance)
   - [:space:] : All whitespace (spaces, tabs, newlines)
   - [:punct:] : All punctuation (.,!?;: etc.)
   - '\n' : Newline character
   - Result: Replaces all spaces and punctuation with newlines
   - Example: "hello, world!" → "hello\nworld"

8. grep -v '^$'
   - -v : Invert match (show lines that DON'T match)
   - '^$' : Regex for empty line (^ = start, $ = end, nothing between)
   - Removes blank lines from output
   - Example Input: "hello\n\nworld\n"
     Output: "hello\nworld"

9. WORDS=$(...)
   - Command substitution with $()
   - Captures output of entire pipeline into WORDS variable
   - Stores one word per line
   - Used to avoid re-processing file multiple times


AWK SCRIPT DETAILED EXPLANATION


awk '{ ... } END { ... }'
   - Pattern-action programming language
   - { ... } : Executes for EACH input line
   - END { ... } : Executes ONCE after all lines processed

Main Block (runs for each word):
{
    words[NR] = $0        # Store word in array (NR = line number)
    len = length($0)      # Calculate word length ($0 = current line)
    sum += len            # Add to running total
    if (NR == 1 || len > max_len) max_len = len    # Track longest
    if (NR == 1 || len < min_len) min_len = len    # Track shortest
}

Line-by-line breakdown:

words[NR] = $0
   - words : Associative array (like a dictionary)
   - NR : Built-in variable = current record (line) number
   - $0 : Built-in variable = entire current line (the word)
   - Stores each word with its line number as key
   - Example: words[1]="hello", words[2]="world"

len = length($0)
   - length() : Built-in function returns string length
   - $0 : Current word
   - Calculates and stores length of current word
   - Example: If $0 is "hello", len becomes 5

sum += len
   - += : Add and assign operator
   - Adds current word length to running total
   - Used later to calculate average: sum/NR

if (NR == 1 || len > max_len) max_len = len
   - NR == 1 : True for first word (initialize max_len)
   - || : OR operator
   - len > max_len : Current word is longer than previous max
   - Updates max_len whenever a longer word is found
   - Example: "cat" (3) → "dog" (3) → "elephant" (8) → max_len=8

if (NR == 1 || len < min_len) min_len = len
   - Similar logic but for shortest word
   - Updates min_len whenever a shorter word is found


END Block (runs once after all words):

if (NR == 0) exit 1
   - NR : Total number of records processed
   - If no words found (empty file), exit with error
   - Prevents division by zero errors

for (i in words) seen[words[i]]++
   - Loops through words array
   - seen : New associative array to count occurrences
   - words[i] : Gets the actual word
   - ++ : Increment operator
   - Result: seen["hello"] = 2 if "hello" appears twice
   - Purpose: Count unique words by using words as keys

unique_count = length(seen)
   - length() on array returns number of keys
   - Counts how many unique words exist
   - Example: seen has keys ["hello", "world", "cat"] → length=3

printf "Unique words: %d\n", unique_count
   - printf : Formatted print (like in C language)
   - %d : Format specifier for integer (decimal)
   - \n : Newline character
   - Prints the count of unique words

for (w in seen) if (length(w) == max_len) printf "  %s\n", w
   - Loops through all unique words in seen array
   - w : Current word
   - if (length(w) == max_len) : Only process words with max length
   - %s : Format specifier for string
   - Prints ALL longest words (not just one)
   - Example: If max_len=8, prints "elephant", "giraffe", etc.

printf "\nAverage length: %.2f chars\n", sum/NR
   - %.2f : Format specifier for float with 2 decimal places
   - sum : Total of all character counts
   - NR : Total number of words
   - sum/NR : Calculates average word length
   - Example: sum=50, NR=10 → prints "5.00 chars"


PIPELINE FLOW VISUALIZATION


Input file: "Hello World! Testing, testing."

Step 1: tr '[:upper:]' '[:lower:]' < "$1"
   → "hello world! testing, testing."

Step 2: tr -s '[:space:][:punct:]' '\n'
   → "hello\nworld\ntesting\ntesting"

Step 3: grep -v '^$'
   → "hello\nworld\ntesting\ntesting"
   (no empty lines to remove in this case)

Step 4: Stored in WORDS variable
   WORDS contains 4 lines (words)

Step 5: Piped to awk
   Processing loop runs 4 times (once per word)
   - Line 1: words[1]="hello", len=5, sum=5, max_len=5, min_len=5
   - Line 2: words[2]="world", len=5, sum=10, max_len=5, min_len=5
   - Line 3: words[3]="testing", len=7, sum=17, max_len=7, min_len=5
   - Line 4: words[4]="testing", len=7, sum=24, max_len=7, min_len=5

Step 6: END block
   - Creates seen array: seen["hello"]=1, seen["world"]=1, seen["testing"]=2
   - unique_count = 3
   - Prints all results


EFFICIENCY COMPARISONS


Basic Version:
- Processes file multiple times (once for longest, once for shortest, etc.)
- Extracts only first longest/shortest word
- Uses multiple commands (awk, sort, head, cut, wc, bc)

Improved Version:
- Processes file ONCE and stores in memory
- Single awk pass calculates everything
- Shows ALL words that tie for longest/shortest
- Faster execution (especially for large files)
- More robust (command-line arguments, error checking)


ERROR HANDLING EXPLAINED


Three-layer validation:
1. Argument count check → Wrong usage
2. File existence check → File not found
3. File size check → Empty file

Each check exits with code 1 (error) if failed
Only proceeds to processing if all checks pass

Example error scenarios:
- ./metrics.sh → "Usage: ./metrics.sh <file>"
- ./metrics.sh missing.txt → "File not found: missing.txt"
- ./metrics.sh empty.txt → "File is empty: empty.txt"
- ./metrics.sh data.txt → Processes normally
